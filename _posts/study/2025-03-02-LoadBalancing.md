---
title: 로드밸런싱 vs 리버스 프록시(L4, L7 차이 포함)
date: 2025-03-02 00:10:00 +09:00
categories: [common_topic]
tags: [common]
# image: 
#   path:
---

## 1. 서론

인터넷과 클라우드 환경이 발전하면서, **고가용성**과 **확장성**을 확보하기 위해 여러 가지 **프록시 및 트래픽 분산 기술**이 등장했습니다.

- **로드밸런서**는 여러 서버에 트래픽을 고르게 분산하여 서비스 연속성을 보장하는 핵심 요소이고,
- **리버스 프록시**는 보안·캐싱·SSL 오프로딩 등 **부가 기능**을 제공함으로써 내부 서버를 보호하고 성능을 높입니다.

또한, 전통적인 **웹 서버**와 **웹 애플리케이션 서버**가 담당하는 역할도 달라, 인프라 구조 설계 시 명확히 이해하고 구분할 필요가 있습니다.

아래에서는 **프록시의 종류**와 역할을 살펴보고, **네트워크 프록시**의 정의, **로드밸런서와 리버스 프록시의 차이**, **웹 서버와 웹 애플리케이션 서버의 차이**, 그리고 **L4 vs L7** 계층별 특징을 중점적으로 다룹니다.

---

## 2. 프록시(Proxy)의 개념과 종류

### 2.1 프록시(Proxy)란?

**프록시**는 클라이언트(사용자)와 목적지 서버(백엔드) 사이에 위치하여 **중간자 역할**을 수행하는 서버 혹은 소프트웨어 구성 요소입니다.

- 클라이언트가 직접 서버에 요청을 보내지 않고, **프록시를 경유**함으로써 IP 주소 은닉, 보안 정책 적용, 캐싱, 트래픽 제어 등의 이점을 얻습니다.

### 2.2 대표적인 프록시 유형

1. **포워드 프록시(Forward Proxy)**
    - 내부 클라이언트가 외부 인터넷에 접근할 때 중간에 위치
    - 클라이언트의 실제 IP 주소를 숨기고, **IP·URL 필터링** 등 정책 적용에 용이
    - 주로 기업 내부망에서 직원들의 웹 접근을 통제하거나 캐싱 서버로 활용
2. **리버스 프록시(Reverse Proxy)**
    - 외부 클라이언트의 요청을 받아 **내부 서버**에 전달
    - 내부 서버 IP를 노출하지 않고 **보안 강화**, **SSL 오프로딩**, **캐싱** 등을 수행
    - 웹 서버를 대체해 **HTTP/HTTPS** 트래픽을 선 처리하는 역할이 많음
3. **투명 프록시(Transparent Proxy)**
    - 클라이언트가 프록시 사용을 **인지하지 못한 상태**로 자동 라우팅
    - 주로 ISP나 게이트웨이 장비에 적용해 트래픽 모니터링, 캐싱 등을 수행

### 2.3 네트워크 프록시의 정의

**네트워크 프록시**는 네트워크 계층에서 패킷을 가로채거나 변환·중계하는 형태로, L4~L7 범위에서 동작하는 경우가 많습니다.

- L4 계층(전송 계층)까지 확인해 **IP/Port**를 기반으로 트래픽 분산 또는 필터링
- L7 계층(애플리케이션 계층)까지 파고들어 **HTTP 헤더, URL** 등을 파악해 세밀한 정책 적용

---

## 3. 로드밸런서(Load Balancer) vs. 리버스 프록시(Reverse Proxy)

로드밸런서와 리버스 프록시는 모두 “**중간에서 트래픽을 받아 내부 서버로 전달**한다”는 점에서 유사하게 보이지만, **주요 목적**과 **핵심 기능**이 다릅니다.

| 구분 | **로드밸런서(Load Balancer)** | **리버스 프록시(Reverse Proxy)** |
| --- | --- | --- |
| **주요 목적** | 여러 서버(노드)로 트래픽을 **분산**하여 **부하(Burden)**를 낮추고 **고가용성** 확보 | 외부 클라이언트가 내부 서버에 직접 접근하지 못하도록 **보안·캐싱·SSL 오프로딩** 등 다양한 기능 제공 |
| **트래픽 분산 알고리즘** | Round Robin, Least Connection, Weighted 등 **부하 분산 기법**이 핵심 | 필요에 따라 단순 분산도 수행 가능하지만, **캐싱/헤더 수정/URL Rewrite** 등 **애플리케이션 레벨** 작업에 강점 |
| **배치 시나리오** | 여러 대의 웹 서버, 앱 서버 등에 대한 **부하 분산** 구간에 배치 | 웹 서비스 앞단에서 **보안 및 트래픽 관리** (웹 방화벽 역할 일부 수행) |
| **확장성(Scalability) & 장애 대응** | 서버 풀(Pool) 헬스 체크, 장애 서버 자동 제외, **수평 확장**(Scale-Out) | 보안·캐싱·SSL 처리로 서버 자원 부담 완화, IP·포트 감춤(네트워크 세부 구조 노출 최소화) |
| **적용 예시** | - Nginx/HAProxy로 LB 구성- AWS ELB, GCP LB 등 클라우드 로드밸런싱- F5 LTM처럼 전용 HW 어플라이언스 | - Nginx/Apache/httpd 등 **Reverse Proxy 모드**- CDN업체(Cloudflare, Akamai 등)에서의 프록시 역할- 방화벽/WAF 연동을 통한 보안 관문 역할 수행 |
- **정리**:
    - “트래픽을 여러 서버로 **분산**”하는 것이 주목적이면 → **로드밸런서**
    - “보안·캐싱·SSL Offloading 등 **부가 기능**이 중요”하면 → **리버스 프록시**

> 실제로 Nginx, HAProxy, F5, Envoy 등은 로드밸런서와 리버스 프록시 기능을 동시에 지원하기도 합니다.
> 

---

## 4. 웹 서버(Web Server) vs. 웹 애플리케이션 서버(Web Application Server)

### 4.1 웹 서버(Web Server)의 역할

- **HTTP 프로토콜**을 통해 **정적 콘텐츠(HTML, CSS, JS, 이미지 등)**를 주로 제공
- 요청 받은 리소스를 직접 응답하거나, 웹 애플리케이션 서버로 요청을 전달(Reverse Proxy 겸용 가능)
- **주요 예시**: Apache HTTP Server(httpd), Nginx, Microsoft IIS, Lighttpd 등

### 4.2 웹 애플리케이션 서버(WAS)의 역할

- **동적 로직**을 처리하고, DB와 연동하여 **동적인 웹 페이지**(예: JSP, Servlet, Ruby on Rails, Django 등) 생성
- 자체적으로 HTTP 요청을 받을 수도 있지만, 대규모 서비스에서는 **웹 서버와 분리**해 확장성과 유지보수성을 높이는 구조가 일반적
- **주요 예시**: Tomcat(Java), JBoss/WildFly, GlassFish, Jetty, WebSphere 등

### 4.3 두 계층 분리의 이유

- **성능 및 확장성**: 정적 파일 처리는 웹 서버가 담당, 동적 로직은 WAS가 집중 처리 → 역할 분배로 효율 증대
- **보안 및 유지보수**: 웹 서버 레벨에서 SSL/TLS, 리버스 프록시, 기본 보안 기능을 수행하고, WAS는 애플리케이션 로직에 집중
- **업데이트 유연성**: 웹 서버와 애플리케이션 서버를 별도로 버전 관리 가능

---

## 5. 리버스 프록시 기능을 제공하는 대표 웹 서버와 장단점

### 5.1 Nginx

- **특징**
    - 이벤트 기반 아키텍처로 **높은 동시성** 처리 가능
    - **Reverse Proxy**, **로드밸런싱**, **캐싱**, **SSL 오프로딩** 등 종합 기능 지원
- **장점**
    - 메모리 사용량이 적고, 대규모 트래픽 환경에서 좋은 성능
    - 설정 구조가 비교적 단순(블록·디렉티브 방식)
- **단점**
    - 복잡한 동적 모듈 로딩이 제한적 (주로 빌드 시 컴파일된 모듈 사용)
    - Apache httpd에 비해 전통적인 .htaccess 활용이 어려움

### 5.2 Apache HTTP Server (httpd)

- **특징**
    - **오랜 역사**와 풍부한 모듈 생태계, 다양한 기능 확장이 용이
    - `mod_proxy`, `mod_ssl`, `mod_rewrite` 등을 통해 리버스 프록시 및 SSL 기능 제공
- **장점**
    - 방대한 커뮤니티, 수많은 모듈로 다양한 요구사항을 충족
    - .htaccess로 디렉터리 단위 설정 가능
- **단점**
    - 프로세스/쓰레드 기반 아키텍처로, **높은 동시 연결** 시 퍼포먼스 저하 우려
    - 설정 파일(httpd.conf)이 복잡하고, 레거시 기능이 많아 학습 곡선이 큼

### 5.3 Caddy

- **특징**
    - Go 언어로 작성된 **모던 웹 서버**로, 간결한 구성
    - **자동 SSL/TLS**(Let’s Encrypt 연동), HTTP/3 지원 등 최신 프로토콜 적극 도입
- **장점**
    - 디폴트로 HTTPS(자동 인증서 발급) 구성 가능 → 설정이 매우 간편
    - Reverse Proxy, 파일 서버 등 역할 수행이 쉬움
- **단점**
    - 에코시스템이 Nginx나 Apache에 비해 작음
    - 특정 커스텀 요구사항에서 확장성 제한

> 이 외에도 Lighttpd, Envoy, HAProxy(L7 모드) 등이 리버스 프록시 기능을 제공할 수 있습니다.
> 

---

## 6. L4 vs L7: 프로토콜 계층에서의 차이

웹 인프라를 구성할 때, 로드밸런서나 프록시가 **어느 계층**(OSI 7계층 기준)에서 동작하는지도 중요한 판단 요소입니다.

### 6.1 L4 (전송 계층) 로드밸런싱

- **동작 원리**
    - TCP/UDP **포트 번호**와 IP 주소 정보를 기반으로 트래픽 분산
    - 패킷 레벨에서 빠른 처리가 가능하며, **지연(latency)**이 상대적으로 낮음
- **장점**
    - 단순하고 고성능 → 대용량 트래픽 처리에 유리
    - 서버 상태(헬스 체크)와 연결 수 기반 분산, VPN/터널링 등 다양한 포트 기반 프로토콜 처리 가능
- **단점**
    - 애플리케이션 레벨 정보를 인지하지 못함 → URL, 쿠키, 헤더 기반 분산 불가
    - 콘텐츠 캐싱이나 SSL 오프로딩 같은 고급 기능은 수행하기 어려움

### 6.2 L7 (애플리케이션 계층) 리버스 프록시/로드밸런싱

- **동작 원리**
    - HTTP/HTTPS 등 **애플리케이션 프로토콜**을 파싱하여 **URL, 헤더, 쿠키**를 기준으로 트래픽 라우팅
    - SSL 복호화 후 정교한 제어 가능
- **장점**
    - **콘텐츠 기반 라우팅**, 캐싱, WAF 연동, 헤더 수정, URL Rewrite 등 다양한 기능
    - 특정 요청(예: /images/)을 전용 서버로 분산하는 등 **유연성**이 매우 높음
- **단점**
    - **프로토콜 파싱**으로 인한 오버헤드 발생
    - 설정·유지보수가 복잡, 실수 시 애플리케이션 동작에 직접적인 영향 가능

### 6.3 요약 비교

| 구분 | **L4 로드밸런싱** | **L7 리버스 프록시/로드밸런싱** |
| --- | --- | --- |
| **동작 계층** | 전송 계층(TCP/UDP) | 애플리케이션 계층(HTTP/HTTPS) |
| **트래픽 제어** | IP/Port 정보 기반 **단순 분산** | HTTP 헤더·쿠키·URL 기반 **정교한 라우팅** 가능 |
| **처리 성능** | 낮은 지연, 고성능 | 프로토콜 파싱으로 인한 오버헤드 가능 |
| **추가 기능** | 세션 지속성(출발지 IP), 헬스 체크 정도 | 캐싱, SSL 오프로딩, 콘텐츠 라우팅, WAF 연동 등 **부가 기능** 다수 |
| **주요 사례** | 게임 서버, 스트리밍, 간단 HTTP 분산 | 전자상거래, 복잡한 웹 앱(동적 컨텐츠), 마이크로서비스(API 게이트웨이) 등 다양한 분야 |

---

## 7. 최신 동향 및 결론

### 7.1 컨테이너·마이크로서비스와의 결합

- **Kubernetes** 등의 오케스트레이션 환경에서, 로드밸런서와 리버스 프록시(예: Ingress Controller, Service Mesh)가 결합되어 **동적 스케일링**과 **세밀한 트래픽 제어**를 구현
- **API 게이트웨이**(Kong, Ambassador, Istio 등) 역시 L7 계층에서 **라우팅·정책 적용·보안**을 수행하는 리버스 프록시 형태

### 7.2 인공지능(AI) 기반 자동화

- 머신러닝을 활용해 **트래픽 패턴**을 분석, 공격이나 이상 징후를 자동 차단하거나 **부하 급증 시 서버 추가**(Auto Scaling)
- 로드밸런서와 리버스 프록시 설정을 **인프라 as Code**(예: Terraform, Ansible)로 관리, CI/CD 파이프라인에 통합

### 7.3 결론

- **로드밸런서**와 **리버스 프록시**는 각각 **부하 분산**과 **보안/캐싱/프로토콜 처리**를 중점으로 발전해 왔지만, 최근에는 하나의 솔루션이 양쪽 기능을 통합 제공하는 사례가 늘어나는 추세입니다.
- **웹 서버**(정적 콘텐츠·Reverse Proxy)와 **웹 애플리케이션 서버**(동적 로직)는 역할이 다르며, 확장성과 보안을 위해 분리 운영하는 것이 일반적입니다.
- **L4 vs L7**: 빠른 처리가 우선이면 L4, 정교한 라우팅·보안이 필요하면 L7을 선택하거나, 하이브리드로 구성해 **상호 보완**할 수도 있습니다.